{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "great tutorial:\n",
    "    https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:03:40.472122Z",
     "start_time": "2020-04-01T14:03:39.855093Z"
    }
   },
   "outputs": [],
   "source": [
    "import re  # For preprocessing\n",
    "import pandas as pd  # For data handling\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "import spacy  # For preprocessing\n",
    "\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# user_id to screen_name conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:03:57.637316Z",
     "start_time": "2020-04-01T14:03:57.148058Z"
    }
   },
   "outputs": [],
   "source": [
    "ud_df = pd.read_pickle('users_with_over_200_DETAILS.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:03:57.834236Z",
     "start_time": "2020-04-01T14:03:57.831450Z"
    }
   },
   "outputs": [],
   "source": [
    "def id_to_name(uid):\n",
    "    return ud_df[ud_df['user_id']==uid]['screen_name'].to_string(index=False).strip()\n",
    "    \n",
    "def name_to_id(name):\n",
    "    uid = ud_df[ud_df['screen_name']==name]['user_id'].to_string(index=False)\n",
    "    return uid.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:03:58.345615Z",
     "start_time": "2020-04-01T14:03:58.300993Z"
    }
   },
   "outputs": [],
   "source": [
    "name_to_id('Starbucks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:03:59.332547Z",
     "start_time": "2020-04-01T14:03:59.293433Z"
    }
   },
   "outputs": [],
   "source": [
    "ud_df[ud_df['user_id']=='30973']['screen_name'].to_string(index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:04:18.670820Z",
     "start_time": "2020-04-01T14:04:18.667134Z"
    }
   },
   "source": [
    "# Read train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:03:41.615531Z",
     "start_time": "2020-04-01T14:03:41.213526Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('train_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:08:38.155629Z",
     "start_time": "2020-04-01T14:08:38.150989Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:17:06.126884Z",
     "start_time": "2020-04-01T14:17:06.120661Z"
    }
   },
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:20:28.663233Z",
     "start_time": "2020-04-01T14:20:28.323708Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clean = pd.DataFrame([' '.join(map(str, line)) for line in train_data] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:20:31.400366Z",
     "start_time": "2020-04-01T14:20:31.397537Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create permutations of the followed users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:22:29.314875Z",
     "start_time": "2020-04-01T14:22:20.241009Z"
    }
   },
   "outputs": [],
   "source": [
    "number_of_shuffles = 5\n",
    "\n",
    "for _ in range(number_of_shuffles):\n",
    "    for line in train_data:\n",
    "        random.shuffle(line)\n",
    "    shuffled_train_df = pd.DataFrame([' '.join(map(str, line)) for line in train_data] )\n",
    "    df_clean = df_clean.append(shuffled_train_df)\n",
    "    \n",
    "print( \"augemented train data length: \" , df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:25:17.841761Z",
     "start_time": "2020-04-01T14:25:17.832279Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clean.rename(columns={0:'clean'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:25:20.722758Z",
     "start_time": "2020-04-01T14:25:20.718517Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clean.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams - not needed for item2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:27:58.673245Z",
     "start_time": "2020-04-01T14:25:25.361509Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "sent = [row.split() for row in df_clean['clean']]\n",
    "phrases = Phrases(sent, min_count=30, threshold =10000 ,progress_per=10000)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:29:11.430367Z",
     "start_time": "2020-04-01T14:28:35.647957Z"
    }
   },
   "outputs": [],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:29:32.823508Z",
     "start_time": "2020-04-01T14:29:32.675858Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:29:38.540353Z",
     "start_time": "2020-04-01T14:29:38.536008Z"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:29:41.450513Z",
     "start_time": "2020-04-01T14:29:41.447885Z"
    }
   },
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:29:44.322715Z",
     "start_time": "2020-04-01T14:29:44.320031Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=2,\n",
    "                     size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vocabolary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:30:51.044263Z",
     "start_time": "2020-04-01T14:29:47.176765Z"
    }
   },
   "outputs": [],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T14:31:27.113854Z",
     "start_time": "2020-04-01T14:31:27.107697Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v_model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time to train 72606 items: 35.25 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T15:06:47.725101Z",
     "start_time": "2020-04-01T14:31:32.525815Z"
    }
   },
   "outputs": [],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compacting the model - only if not going to train it further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:38:36.729989Z",
     "start_time": "2020-03-30T19:38:36.698243Z"
    }
   },
   "outputs": [],
   "source": [
    "#w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the model for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T15:10:30.870251Z",
     "start_time": "2020-04-01T15:10:30.336429Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v_model.save(\"word2vec_v2.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T15:10:34.060864Z",
     "start_time": "2020-04-01T15:10:33.859477Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"180505807\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T15:10:41.974830Z",
     "start_time": "2020-04-01T15:10:41.709034Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T15:10:44.842705Z",
     "start_time": "2020-04-01T15:10:44.832874Z"
    }
   },
   "outputs": [],
   "source": [
    "def tsnescatterplot(model, word, list_names):\n",
    "    \"\"\" Plot in seaborn the results from the t-SNE dimensionality reduction algorithm of the vectors of a query word,\n",
    "    its list of most similar words, and a list of words.\n",
    "    \"\"\"\n",
    "    arrays = np.empty((0, 300), dtype='f')\n",
    "    word_labels = [word]\n",
    "    color_list  = ['red']\n",
    "\n",
    "    # adds the vector of the query word\n",
    "    arrays = np.append(arrays, model.wv.__getitem__([word]), axis=0)\n",
    "    \n",
    "    # gets list of most similar words\n",
    "    close_words = model.wv.most_similar([word])\n",
    "    \n",
    "    # adds the vector for each of the closest words to the array\n",
    "    for wrd_score in close_words:\n",
    "        wrd_vector = model.wv.__getitem__([wrd_score[0]])\n",
    "        word_labels.append(wrd_score[0])\n",
    "        color_list.append('blue')\n",
    "        arrays = np.append(arrays, wrd_vector, axis=0)\n",
    "    \n",
    "    # adds the vector for each of the words from list_names to the array\n",
    "    for wrd in list_names:\n",
    "        wrd_vector = model.wv.__getitem__([wrd])\n",
    "        word_labels.append(wrd)\n",
    "        color_list.append('green')\n",
    "        arrays = np.append(arrays, wrd_vector, axis=0)\n",
    "    \n",
    "    #my part -- foo = [a + 42 for a in foo]\n",
    "\n",
    "    word_labels = [ud_df[ud_df['user_id']==wrd]['screen_name'].to_string(index=False) for wrd in word_labels]\n",
    "    \n",
    "    \n",
    "    # Reduces the dimensionality from 300 to 50 dimensions with PCA\n",
    "    # was:  reduc = PCA(n_components=50).fit_transform(arrays)\n",
    "    reduc = PCA(n_components=20).fit_transform(arrays)\n",
    "    \n",
    "    # Finds t-SNE coordinates for 2 dimensions\n",
    "    np.set_printoptions(suppress=True)\n",
    "    \n",
    "    Y = TSNE(n_components=2, random_state=0, perplexity=15).fit_transform(reduc)\n",
    "    \n",
    "    # Sets everything up to plot\n",
    "    df = pd.DataFrame({'x': [x for x in Y[:, 0]],\n",
    "                       'y': [y for y in Y[:, 1]],\n",
    "                       'words': word_labels,\n",
    "                       'color': color_list})\n",
    "    \n",
    "    fig, _ = plt.subplots()\n",
    "    fig.set_size_inches(9, 9)\n",
    "    \n",
    "    # Basic plot\n",
    "    p1 = sns.regplot(data=df,\n",
    "                     x=\"x\",\n",
    "                     y=\"y\",\n",
    "                     fit_reg=False,\n",
    "                     marker=\"o\",\n",
    "                     scatter_kws={'s': 40,\n",
    "                                  'facecolors': df['color']\n",
    "                                 }\n",
    "                    )\n",
    "    \n",
    "    # Adds annotations one by one with a loop\n",
    "    for line in range(0, df.shape[0]):\n",
    "         p1.text(df[\"x\"][line],\n",
    "                 df['y'][line],\n",
    "                 '  ' + df[\"words\"][line].title(),\n",
    "                 horizontalalignment='left',\n",
    "                 verticalalignment='bottom', size='medium',\n",
    "                 color=df['color'][line],\n",
    "                 weight='normal'\n",
    "                ).set_size(15)\n",
    "\n",
    "    \n",
    "    plt.xlim(Y[:, 0].min()-50, Y[:, 0].max()+50)\n",
    "    plt.ylim(Y[:, 1].min()-50, Y[:, 1].max()+50)\n",
    "            \n",
    "    plt.title('t-SNE visualization for {}'.format(word.title()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Most similar words vs. 10 Most dissimilar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T15:17:26.155046Z",
     "start_time": "2020-04-01T15:17:25.418498Z"
    }
   },
   "outputs": [],
   "source": [
    "def ten_most_similar(wrd):\n",
    "    uid = name_to_id(wrd)\n",
    "    #uid = ud_df[ud_df['screen_name']==wrd]['user_id'].to_string(index=False)\n",
    "    #uid = uid.strip()\n",
    "    tsnescatterplot(w2v_model, uid, [i[0] for i in w2v_model.wv.most_similar(negative=[uid])])\n",
    "\n",
    "ten_most_similar('GalGadot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Harvard\n",
    "Target\n",
    "CNN\n",
    "Apple\n",
    "BarackObama\n",
    "united\n",
    "ABC\n",
    "ArianaGrande\n",
    "NYGovCuomo\n",
    "KimKardashian\n",
    "Starbucks\n",
    "\n",
    "\n",
    "check these ids:\n",
    "    25073877 => @realDonaldTrump\n",
    "180505807 => @instagram\n",
    "25365536 => @KimKardashian\n",
    "79293791 => @rihanna\n",
    "28603812 => @Royals\n",
    "\n",
    "@billgates => 50393960\n",
    "@cnn => 759251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:18:17.433564Z",
     "start_time": "2020-03-30T19:18:16.128944Z"
    }
   },
   "outputs": [],
   "source": [
    "tsnescatterplot(w2v_model, '759251', [i[0] for i in w2v_model.wv.most_similar(negative=[\"759251\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load from drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T13:51:51.823559Z",
     "start_time": "2020-04-01T13:51:51.384678Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T13:51:52.554653Z",
     "start_time": "2020-04-01T13:51:52.117082Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"word2vec_v1.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bitc826dcc705f3421fa626a7aa062cf49f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "469px",
    "left": "948px",
    "right": "20px",
    "top": "110px",
    "width": "382px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
